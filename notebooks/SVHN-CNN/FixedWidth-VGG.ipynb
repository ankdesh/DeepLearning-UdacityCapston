{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 32 # Side for each transformed Image\n",
    "IMG_HEIGHT = 32\n",
    "IMG_DEPTH = 1 # RGB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_LABELS = 3\n",
    "h5FileName = 'svhn_' + str(NUM_LABELS) + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = h5py.File(h5FileName)\n",
    "imgs = np.array(data['images']).astype(float)\n",
    "labels = np.array(data['digits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (type(imgs))\n",
    "print (labels.shape)\n",
    "print (imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (labels[0])\n",
    "plt.imshow(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    index_update = [int(x) for x in index_offset + labels_dense.ravel()]\n",
    "    labels_one_hot.flat[index_update] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "X = imgs.reshape([-1, IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH])\n",
    "Y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate validation set\n",
    "ratio = 0.9 # Train/Test set\n",
    "randIdx = np.random.random(imgs.shape[0]) <= ratio\n",
    "#print (sum(map(lambda x: int(x), randIdx)))\n",
    "X_train = X[randIdx]\n",
    "Y_train = Y[randIdx]\n",
    "X_test = X[randIdx == False]\n",
    "Y_test = Y[randIdx == False]\n",
    "Y_train = [dense_to_one_hot(Y_train[:,idx], num_classes= 10) for idx in range(Y_train.shape[1])] \n",
    "Y_test = [dense_to_one_hot(Y_test[:,idx], num_classes= 10) for idx in range(Y_test.shape[1])] \n",
    "#del X, Y # release some space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (X_train.shape)\n",
    "print (Y_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print (np.mean(Y_train[1], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building convolutional network\n",
    "\n",
    "# Building convolutional network\n",
    "for numLayers in [1,2,3,4,5]: # Num of Conv layer sets to use\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        # Real-time data preprocessing\n",
    "        img_prep = ImagePreprocessing()\n",
    "        img_prep.add_featurewise_zero_center()\n",
    "        img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "        # Real-time data augmentation\n",
    "        img_aug = ImageAugmentation()\n",
    "        #img_aug.add_random_flip_leftright()\n",
    "        img_aug.add_random_rotation(max_angle=25.)\n",
    "        input = input_data(shape=[None, IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH], name='input',\n",
    "                                                                    data_preprocessing=img_prep,\n",
    "                                                                    data_augmentation=img_aug)\n",
    "\n",
    "        # Building convolutional network\n",
    "        x = tflearn.conv_2d(input, 32, 3, activation='relu', name='conv1_1')\n",
    "        x = tflearn.conv_2d(x, 32, 3, activation='relu', name='conv1_2')\n",
    "        x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool1')\n",
    "        #x = local_response_normalization(x)\n",
    "\n",
    "        if numLayers >= 2:\n",
    "            x = tflearn.conv_2d(x, 64, 3, activation='relu', name='conv2_1')\n",
    "            x = tflearn.conv_2d(x, 64, 3, activation='relu', name='conv2_2')\n",
    "            x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool2')\n",
    "            #x = local_response_normalization(x)\n",
    "    \n",
    "        if numLayers >= 3:\n",
    "            x = tflearn.conv_2d(x, 256, 3, activation='relu', name='conv3_1')\n",
    "            x = tflearn.conv_2d(x, 256, 3, activation='relu', name='conv3_2')\n",
    "            x = tflearn.conv_2d(x, 256, 3, activation='relu', name='conv3_3')\n",
    "            x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool3')\n",
    "\n",
    "        if numLayers >= 4:\n",
    "            x = tflearn.conv_2d(x, 512, 3, activation='relu', name='conv4_1')\n",
    "            x = tflearn.conv_2d(x, 512, 3, activation='relu', name='conv4_2')\n",
    "            x = tflearn.conv_2d(x, 512, 3, activation='relu', name='conv4_3')\n",
    "            x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool4')\n",
    "\n",
    "        if numLayers >= 5:\n",
    "            x = tflearn.conv_2d(x, 512, 3, activation='relu', name='conv5_1')\n",
    "            x = tflearn.conv_2d(x, 512, 3, activation='relu', name='conv5_2')\n",
    "            x = tflearn.conv_2d(x, 512, 3, activation='relu', name='conv5_3')\n",
    "            x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool5')\n",
    "\n",
    "        # Training heads\n",
    "        allHeads = []\n",
    "        for idx in range(NUM_LABELS):\n",
    "            fc = fully_connected(x, 1024, activation='tanh')\n",
    "            #fc = dropout(fc, 0.8)\n",
    "            #fc = fully_connected(fc, 1024, activation='tanh')\n",
    "            #fc = dropout(fc, 0.8)\n",
    "            softmax = fully_connected(fc, 10, activation='softmax')\n",
    "            networkOut = regression(softmax, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy', name='target' + str(idx))\n",
    "            allHeads.append(networkOut)\n",
    "\n",
    "        network = tflearn.merge(allHeads, mode='elemwise_sum')\n",
    "\n",
    "        model = tflearn.DNN(network, tensorboard_verbose=5)\n",
    "        feedTrainDict = {'target'+ str(i): Y_train[i] for i in range(NUM_LABELS)}\n",
    "        #feedTrainDict = {'target0': Y_train[0]}\n",
    "        feedTestList =  [Y_test[i] for i in range(NUM_LABELS)]\n",
    "        #feedTestList =  Y_test[0]\n",
    "        model.fit({'input': X_train}, feedTrainDict, \n",
    "                  validation_set= (X_test, feedTestList), n_epoch=3, show_metric=True, \n",
    "                  run_id='convnet_svhn_' + str(numLayers))\n",
    "        #with open('/tmp/tflearn_logs/resultsLayer.txt','a') as f:\n",
    "        #    strRes = str(numLayers) + ' -> ' + str(model.evaluate([X_test], feedTestList))\n",
    "        #    f.write(strRes)\n",
    "        #model.fit({'input': X_train}, feedTrainDict, n_epoch=1, show_metric=True, run_id='convnet_mnist')\n",
    "        #model.fit({'input': X_train}, {'target0': Y_train[1]}, n_epoch=1, show_metric=True, run_id='convnet_mnist')\n",
    "        #numImgEachAxis = 8\n",
    "        #f,ax = plt.subplots(numImgEachAxis, numImgEachAxis, figsize=(10,10))\n",
    "        #for i in range(numImgEachAxis):\n",
    "        #    for j in range(numImgEachAxis):\n",
    "        #        res = np.array([np.argmax(x) for x in model.predict([X_train[i*numImgEachAxis + j]])])\n",
    "        #        print (str(i) + ',' + str(j) + ' -> ' +str(res))\n",
    "                #ax[i][j].set_title(str([np.round(x,2) for x in res]))\n",
    "        #        ax[i][j].imshow(X_train[i*numImgEachAxis + j].reshape((IMG_HEIGHT,IMG_WIDTH)) ,cmap = 'gray')\n",
    "        #plt.show() # or display.display(plt.gcf()) if you prefer\n",
    "    #    print (model.evaluate(X_test,feedTestList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
