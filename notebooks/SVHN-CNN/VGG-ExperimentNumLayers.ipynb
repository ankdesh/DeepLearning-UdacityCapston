{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import LoadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 128 # Side for each transformed Image\n",
    "IMG_HEIGHT = 64\n",
    "IMG_DEPTH = 3 # RGB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATSET_SIZE =  LoadDataset.getNumPngFiles()\n",
    "NUM_LABELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = LoadDataset.getDataSet(DATSET_SIZE, NUM_LABELS)\n",
    "imgs = data[0]\n",
    "labels = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    index_update = [int(x) for x in index_offset + labels_dense.ravel()]\n",
    "    labels_one_hot.flat[index_update] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "X = imgs.reshape([-1, IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH])\n",
    "Y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate validation set\n",
    "ratio = 0.8 # Train/Test set\n",
    "randIdx = np.random.random(DATSET_SIZE) <= ratio\n",
    "#print (sum(map(lambda x: int(x), randIdx)))\n",
    "X_train = X[randIdx]\n",
    "Y_train = Y[randIdx]\n",
    "X_test = X[randIdx == False]\n",
    "Y_test = Y[randIdx == False]\n",
    "Y_train = [dense_to_one_hot(Y_train[:,idx], num_classes= 11) for idx in range(Y_train.shape[1])] \n",
    "Y_test = [dense_to_one_hot(Y_test[:,idx], num_classes= 11) for idx in range(Y_test.shape[1])] \n",
    "del X, Y # release some space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building convolutional network\n",
    "network = input_data(shape=[None, IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH], name='input')\n",
    "\n",
    "# Building convolutional network\n",
    "network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "\n",
    "\n",
    "# Training heads\n",
    "allHeads = []\n",
    "for idx in range(NUM_LABELS):\n",
    "    fc = fully_connected(network, 128, activation='tanh')\n",
    "    fc = dropout(fc, 0.8)\n",
    "    softmax = fully_connected(fc, 11, activation='softmax')\n",
    "    networkOut = regression(softmax, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target' + str(idx))\n",
    "    allHeads.append(networkOut)\n",
    "\n",
    "network = tflearn.merge(allHeads, mode='elemwise_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2090  | total loss: \u001b[1m\u001b[32m6.08579\u001b[0m\u001b[0m\n",
      "| Adam_0 | epoch: 005 | loss: 1.19094 - acc: 0.7056 | val_loss: 1.20390 - val_acc: 0.6974 -- iter: 26703/26703\n",
      "| Adam_1 | epoch: 005 | loss: 2.41184 - acc: 0.1409 | val_loss: 2.38770 - val_acc: 0.1558 -- iter: 26703/26703\n",
      "| Adam | epoch: 005 | loss: 2.48301 - acc: 0.1040 | val_loss: 2.44226 - val_acc: 0.1002 -- iter: 26703/26703\n",
      "Training Step: 2090  | total loss: \u001b[1m\u001b[32m6.08579\u001b[0m\u001b[0m\n",
      "| Adam_0 | epoch: 005 | loss: 1.19094 - acc: 0.7056 | val_loss: 1.20390 - val_acc: 0.6974 -- iter: 26703/26703\n",
      "| Adam_1 | epoch: 005 | loss: 2.41184 - acc: 0.1409 | val_loss: 2.38770 - val_acc: 0.1558 -- iter: 26703/26703\n",
      "| Adam | epoch: 005 | loss: 2.48301 - acc: 0.1040 | val_loss: 2.44226 - val_acc: 0.1002 -- iter: 26703/26703\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(network, tensorboard_verbose=1)\n",
    "feedTrainDict = {'target'+ str(i): Y_train[i] for i in range(NUM_LABELS)}\n",
    "feedTestList =  [Y_test[i] for i in range(NUM_LABELS)]\n",
    "model.fit({'input': X_train}, feedTrainDict, \n",
    "          validation_set= (X_test, feedTestList), n_epoch=5, snapshot_step=100, show_metric=True, run_id='convnet_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
